{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Stroke Prediction Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "data = pd.read_csv('./train_strokes.csv')\n",
    "df = data.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform format\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# check for duplicate data based on ['id']\n",
    "df.duplicated('id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature ['id'] is not needed for analysis\n",
    "df.drop(['id'], axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['age', 'avg_glucose_level', 'bmi']\n",
    "categorical_cols = df.columns.drop(numeric_cols)\n",
    "\n",
    "# check unique values of categorical variables\n",
    "for col in df[categorical_cols]:\n",
    "    print(f'{col} : {df[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check ratio of target feature ['stroke']\n",
    "print(df.stroke.value_counts(), df.stroke.value_counts(normalize=True)*100, sep='\\n\\n')\n",
    "\n",
    "# Imbalanced data for target variable ['stroke']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stroke by Age, Average Glucose Level, and BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numeric_cols = ['age', 'avg_glucose_level', 'bmi']\n",
    "# categorical_cols = 'gender', 'hypertension', 'heart_disease', 'ever_married',\n",
    "#                    'work_type','residence_type', 'smoking_status', 'stroke']\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, figsize=(15,10))\n",
    "sns.set_theme()\n",
    "\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    sns.histplot(df, x=col, hue='stroke', kde=True, bins=25, multiple='stack', ax=axs[i, 0])\n",
    "    sns.boxplot(df, x=col, ax=axs[i, 1], )\n",
    "    sns.scatterplot(df, x=col, y='stroke', ax=axs[i,2])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stroke by Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(categorical_cols)//4, 4, figsize=(15, 10))\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "        ax = sns.countplot(df, x=col, hue='stroke', ax=axs[i // 4, i % 4])\n",
    "        ax.set_title(col)\n",
    "        ax.tick_params(axis='x', rotation=30)\n",
    "\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check values in ['gender']\n",
    "print(df['gender'].value_counts())\n",
    "\n",
    "# drop 'Other' values in ['gender'] due to insufficient data\n",
    "df = df[df['gender']!='Other']\n",
    "\n",
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of ['bmi']\n",
    "sns.boxplot(x=df['bmi'])\n",
    "print(df['bmi'].describe())\n",
    "\n",
    "# due to outliers, replace missing values with median\n",
    "median = df['bmi'].median()\n",
    "print(f'\\nmedian: {median}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing data in ['bmi'] with median\n",
    "df['bmi'].fillna(median, inplace=True)\n",
    "\n",
    "# reassign missing values of ['smoking_status'] as 'unknown' instead of dropping\n",
    "df['smoking_status'].fillna('unknown', inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorize numerical variables based on criteria by CDC\n",
    "def categorize_num_var(df):\n",
    "    # categorize ['avg_glucose_level']\n",
    "    df['avg_glucose_level'] = pd.cut(x=df['avg_glucose_level'], \n",
    "                                     bins=[0, 100, 126, np.inf], \n",
    "                                     labels=['normal', 'prediabetic', 'diabetic'])\n",
    "    # categorize ['bmi']\n",
    "    df['bmi'] = pd.cut(x=df['bmi'],\n",
    "                       bins=[0, 18.5, 25, 30, np.inf],\n",
    "                       labels=['underweight', 'normal', 'overweight', 'obese'])\n",
    "    \n",
    "categorize_num_var(df)\n",
    "\n",
    "# check unique values of categorical variables\n",
    "for col in df.drop(['age'], axis=1):\n",
    "    print(f'{col} : {df[col].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data into adequate data types\n",
    "def convert_dtypes(df):\n",
    "    for col in df.drop('age', axis=1):\n",
    "        df[col] = df[col].astype('category')\n",
    "    df['age'] = df['age'].astype('int')\n",
    "\n",
    "    return df.dtypes\n",
    "\n",
    "convert_dtypes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling - Without Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differentiate feature variables & target variable\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "\n",
    "\"\"\"It is important to split data before resampling to retain original data distribution.\n",
    "Resampling to adjust data imbalance is only applied to the train data to improve the accuracy of ML models, not the test data.\"\"\"\n",
    "# split train & validation data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=0, stratify=y)\n",
    "\n",
    "print(f\"Train dataset-{y_train.value_counts()} \\n\\nTest dataset-{y_test.value_counts()} \\n\")\n",
    "print(f\"Train dataset-{y_train.value_counts(normalize=True)*100} \\n\\nTest dataset-{y_test.value_counts(normalize=True)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale & encode appropriate variables\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', MinMaxScaler(), ['age']),\n",
    "        ('cat', OrdinalEncoder(), X_train.columns.drop('age'))\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_train_transformed = pd.DataFrame(transformer.fit_transform(X_train), columns=transformer.get_feature_names_out())\n",
    "X_test_transformed = pd.DataFrame(transformer.transform(X_test), columns=transformer.get_feature_names_out()) \n",
    "\n",
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"SVC\": SVC(probability=True, random_state=0),\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=0),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=0, n_jobs=-1),\n",
    "    \"KNearestNeighbors\": KNeighborsClassifier(n_jobs=-1),\n",
    "    \"MLPClassifier\": MLPClassifier(random_state=0),\n",
    "    \"XGBoosting\": XGBClassifier(eval_metric='auc', random_state=0, n_jobs=-1),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=0),\n",
    "    \"SGDClassifier\": SGDClassifier(loss='log_loss',random_state=0, n_jobs=-1),\n",
    "    \"AdaBoost\": AdaBoostClassifier(random_state=0)\n",
    "    \n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_transformed, y_train)\n",
    "    print(f\"{name} trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test_transformed)\n",
    "    print('-'*80)\n",
    "    # classification report\n",
    "    print(f\"Model Performance - {name} \\n\\n {classification_report(y_test, y_pred, zero_division=0)}\")\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap='Blues')\n",
    "    plt.title(f\"{name}\", fontsize= 15, weight='bold')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    #ROC-AUC Curve\n",
    "    y_pred_proba = model.predict_proba(X_test_transformed)[:, 1]\n",
    "    fpr, tpr, threshholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.title(name, fontsize=15, weight='bold')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.xlabel('FPR')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"{name} - AUC Score: {metrics.roc_auc_score(y_test, y_pred_proba)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    #ROC-AUC Curve\n",
    "    y_pred_proba = model.predict_proba(X_test_transformed)[::, 1]\n",
    "    fpr, tpr, threshholds = roc_curve(y_test, y_pred_proba)\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred_proba).round(4)\n",
    "    plt.plot(fpr,tpr, label=f\"{name}, AUC={auc}\")\n",
    "\n",
    "    # plt.ylabel('TPR')\n",
    "    # plt.xlabel('FPR')\n",
    "    # plt.show()\n",
    "\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('AUC-ROC Curve Performance', fontsize=15, weight='bold')\n",
    "plt.legend(loc=(1.04, 0))\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling - With Resampling(SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train_sampled, y_train_sampled = SMOTE(random_state=0).fit_resample(X_train, y_train)\n",
    "\n",
    "print(y_train.value_counts())\n",
    "# X_train_transformed = pd.DataFrame(transformer.fit_transform(X_train_sampled), columns=transformer.get_feature_names_out())\n",
    "# X_test_transformed = pd.DataFrame(transformer.transform(X_test), columns=transformer.get_feature_names_out())\n",
    "\n",
    "# X_train_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differentiate feature variables & target variable\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "\n",
    "\"\"\"It is important to split data before resampling to retain original data distribution.\n",
    "Resampling to adjust data imbalance is only applied to the train data to improve the accuracy of ML models, not the test data.\"\"\"\n",
    "# split train & validation data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=0, stratify=y)\n",
    "\n",
    "print(f\"Train dataset-{y_train.value_counts()} \\n\\nTest dataset-{y_test.value_counts()} \\n\")\n",
    "print(f\"Train dataset-{y_train.value_counts(normalize=True)*100} \\n\\nTest dataset-{y_test.value_counts(normalize=True)*100}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stroke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
